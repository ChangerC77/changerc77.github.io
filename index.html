<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Xiangyu Chen - Homepage</title>
    
    <meta name="author" content="Xiangyu Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Xiangyu Chen (ÈôàÁøîÂÆá)</name>
                </p>
                <p style="text-align:justify;">
                  I am currently spending my gap year as a research assistant supervised by <a href="https://www.cityu.edu.hk/mne/people/academic-staff/prof-yin-peng">Prof.Peng Yin</a> at <a href="https://metaslam.github.io/">GAIRLAB</a>, City University of Hong Kong (CityU). Currently, I am also a research intern in EncoSmart, focusing on learning-based method for robot manipulation according to visual representation.
                  Previously, I was a research intern at ARX, <a href="https://www.discover-lab.com/">DISCOVER Lab</a>, <a href="https://air.tsinghua.edu.cn/en/"><b>Institute for AI Industry Research (AIR), Tsinghua University</b></a>.
                  where I was fortunate to work closely with <a href="https://scholar.google.com/citations?user=alz2MpAAAAAJ&hl=zh-CN&oi=sra">Dr. Yongliang Shi</a>, and <a href="https://air.tsinghua.edu.cn/info/1046/1199.htm">Prof. Guyue Zhou</a> to study SLAM and Planning. 
                  Piror to that, I obtained First Class Honour Bachelor degree in Electrical and Electronic Engineering from Liverpoor John Moores University in UK.
                  <p>
                  <b><strong>I am actively applying for master degree and looking for the PhD opportunity in Fall 2025.</strong></b>
                  </p>
                <!-- <p style="text-align:center">
                    <a href="mailto:liweize0224@gmail.com"><b>Email</b></a> &nbsp/&nbsp
                    <a href="WeizeLi_04.02.pdf"><b>CV</b></a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=CyPiUucAAAAJ&hl=en-US"><b>Google Scholar</b></a> &nbsp/&nbsp
                    <a href="https://github.com/EricLee0224/"><b>GitHub</b></a> &nbsp/&nbsp
                    <a href="https://twitter.com/WeizeLi24"><b>X</b></a> -->
                </p>
              </td>
              <td style="padding:2.5%;width:48%;max-width:48%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/avator.jpg" class="hoverZoomLink"></a>
              </td>
	      </tr>
	      </table>
	
<!-- -------------------------- NEWS ------------------------------ -->

<!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>News</heading>
    <p>
      <li style="margin: 5px;" >
        <b>2023-09:</b>üéâPAD was accepted to NeurIPS 2023 as Poster!
      </li>
      <li style="margin: 5px;" >
        <b>2023-08:</b>üòéWelcome to <a href="https://github.com/EricLee0224/awesome-nerf-editing">awesome-nerf-editing</a>, find resource for exploring 3D editing!
      </li>
      <li style="margin: 5px;" >
        <b>2023-06:</b>üë®‚Äçüéì<a href="https://pku.ai/">PKU CoRe Lab</a> Visiting! Many thanks to Prof. <a href="https://yzhu.io/">Yixin Zhu</a>'s advices on my future study.
      </li>
      <li style="margin: 5px;" >
        <b>2023-02:</b>üéâIRFLMDNN was accepted to Neural Computing & Applications!
      </li>
      <li style="margin: 5px;" >
        <b>2022-10:</b>üéâMy graduation dissertation was selected as 2022 Beijing Outstanding Undergraduate Dissertation Award (top1%)!
      </li>
      <li style="margin: 5px;" >
        <b>2022-10:</b>üéâI successfully defended Summer Research: McADTR. Thanks to my advisors and Prof. <a href="https://ericyi.github.io/">Li Yi</a>'s insightful comments.
      </li>
      <li style="margin: 5px;" >
        <b>2022-08:</b>üòÆ‚Äçüí®I finished my visiting at CASIA and it was a pleasure to work with Lei, Yu, Xiaomeng and Xiaomin!
      </li>
    </p>
  </td>
</tr>
</tbody></table> -->

<!--  ------------------------ Research ------------------------------>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>Research Interests</heading>
    <!-- <p style="text-align:justify;">
      My long-term research goal is to build <strong>Embodied Intelligent Systems</strong> that can effectively understand 3D worlds from an egocentric perspective, interact with the real world, and utilize 3D AI-generated content (AIGC) to construct endless learnable data, from objects to scenes, for closed-loop embodied intelligence.
      So I am up for anything related research and currently focusing on {3D Vision, Graphics, Robotics} for Embodied AI:
    </p> -->
    <p>
      <li style="margin: 5px;"> 
        ü§ñ<strong>Robotics</strong>
      </li>
      <li style="margin: 5px;"> 
        <strong>Embodied AI</strong>
      </li>
      <li style="margin: 5px;"> 
        <strong>Motion Planning</strong>
      </li>
      <li style="margin: 5px;"> 
        <strong>Robot Learning</strong>
      </li>
      <li style="margin: 5px;"> 
        <strong>Manipulation</strong>
      </li>
    </p>
  </td>
</tr>

<!--  ----------------------- PUBLICATIONS --------------------------  -->
</tbody></table><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Publications</heading>
    </td>
  </tr>
<!-- 	(<sup>‚Ä†</sup>: corresponding author; <sup>*</sup>: equal contribution) -->
</tbody></table>	

(<sup>‚Ä†</sup>: corresponding author; <sup>*</sup>: equal contribution)
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:14px;width:45%;max-width:45%" align="top">
        <img style="width:100%;max-width:100%" src="images/gaussiangrasper.gif" alt="dise">
    </td>
    <td width="75%" valign="center">
      <a href="https://mrsecant.github.io/GaussianGrasper/"><papertitle>GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping</papertitle></a>
      <br>
        Yuhang Zheng,
        <strong>Xiangyu Chen</strong>,
        Yupeng Zheng,
        Songen Gu,
        Runyi Yang,
        Bu Jin,
        Pengfei Li,
        Chengliang Zhong,
        Zengmao Wang,
        Lina Liu,
        Chao Yang,
        Dawei Wang,
        Zhen Chen,
        Xiaoxiao Long<sup>‚Ä†</sup>,
        Meiqing Wang<sup>‚Ä†</sup>.
      <br>
      <strong><em>RA-L, 2024</em></strong>
      <br>
      <a href="https://mrsecant.github.io/GaussianGrasper"><b>[Homepage]</b></a>
      <a href="https://arxiv.org/abs/2403.09637"><b>[arXiv]</b></a>
      <a href="https://github.com/MrSecant/GaussianGrasper"><b>[Code]</b></a>
      <br>
      <p>We introduced GaussianGrasper, a robot grasping system implemented by a 3D Gaussian field endowed with open-vocabulary semantics and accurate geometry that is capable of rapid updates to support open-world robotic grasping guided by language.</p>	
    </td>
  </tr>

<!--  ------------------------ Patents --------------------------  -->
  
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patents</heading>
              <p>
                <li style="margin: 5px;"> 
                  <b>Power low frequency oscillation data anomaly monitoring system v1.0[s]</b>, CN Software Patent No.2022SR0277090
                </li>
                <li style="margin: 5px;"> 
                  <b>Power low frequency oscillation data acquisition system v1.0[s]</b>, CN Software Patent No.2022SR0281546
                </li>
              </p>
            </td>
          </tr>
        </tbody></table> -->
		
<!--  ------------------------ PROJECTS --------------------------  -->

          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Projects</heading>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/survey_teaser.jpg" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Radiance Field-Based 3D Editing: A Survey</b></papertitle>
                <br>
              				<strong>Xiangyu Chen<sup>*</sup></strong>,
					<a href="https://tianshukuai.github.io/">Tianshu Kuai<sup>*</sup></a>,
					<a href="https://c7w.tech/about/">Huan-ang Gao</a>,
					<a href="https://www.eca.ed.ac.uk/profile/trina-tian">Siyu Tian</a>,
					<a href="https://scholar.google.com/citations?user=Wn2Aic0AAAAJ&hl=en">Yuhang Zheng</a>,
					<a href="https://scholar.google.com/citations?user=anGhGdYAAAAJ&hl=en">Yupeng Zheng</a>,etc.
		<br>
                <strong><em>On-going, 2024</em></strong>
                <br>
                <a href="https://github.com/EricLee0224/awesome-nerf-editing"><b>[Project Page]</b></a>
		<br>
                <p>This is an ongoing survey paper and we are conducting a systematic classification and in-depth analysis for 3D content editing based on radiance field representations (including NeRFs, 3DGS, etc.).</p>
              </td>
            </tr>

            <tr>
                <td style="padding:14px;width:30%;max-width:30%" align="center">
                    <img style="width:100%;max-width:100%" src="./images/zero12car.png" alt="dise">
                </td>
                <td width="75%" valign="center">
                    <papertitle><b>Zero1-to-Car: Finetuning Zero1-to-3 for Single Vehicle Image to 3D.</b></papertitle>
                    <br>
		    <em>AIR Research Project. 2023</em>
		    <br>
                    <a href="https://github.com/EricLee0224/"><b>[Coming soon]</b></a>
		    <br>
                    <p>Investigated one‚Äëimage‚Äëto‚Äë3D methods like Zero1‚Äëto‚Äë3 to enhance the quality of multi‚Äëview car instances in simulation scenes, with a focus on fine‚Äëtuning models using the ‚ÄùCar‚Äù labeled 3D assets from the Objaverse dataset.</p>
                </td>

		 <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/mcadtr.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>McADTR: Multi-class Anomaly Detection TRansformer with Heterogenous Knowledge Distillation.</b></papertitle>
                <br>
		<em>AIR Summer Research 2022</em>
		<br>
                <a href="https://github.com/EricLee0224/McADTR"><b>[Code]</b></a>
		<br>
                <p>This project proposes a unified framework for visual anomaly detection based on heterogeneous knowledge distillation. The One-model-all class framework merges CNN and ViT with class-specific learnable query to enable mutually facilitated learning of anomalous features across multi-class samples.</p>
              </td>
            </tr>
		
            </tr> -->

        <!--  ------------------------ Service -------------------------- -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Service</heading>
            <p style="text-align:justify;">
              I served / was delegated as Reviewer for NeurIPS‚Äô23, CVPR‚Äô24, IJCV.
            </p>
          </td>
        </tr> -->
		  
<!--  ------------------------ AWARDS --------------------------  -->
  
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards</heading>
              <p>
                <li style="margin: 5px;"> 
                  <b>Outstanding Undergraduate Dissertation Award, Beijing Education Commission (top 1% in 130,000 students, 2022)</b>
                </li>
                <li style="margin: 5px;"> 
                  Silver Award, Beijing Challenge Cup: Entrepreneurial Plan Competition in AI System Track (Rank.2, 2022)
                </li>
              </p>
            </td>
          </tr>
        </tbody></table> -->

        <!--  ------------------------ MISC -------------------------- -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Misc.</heading>
            <p style="text-align:justify;">
              Outside of research, I enjoy playing football‚öΩ, fitnessüí™ and photographyüì∑. I am a member of the Certified Refereeüó£Ô∏è Crew of the Chinese Football Association. I am also a big fan of Taylor Swiftü¶ã.
            </p>
          </td>
        </tr> -->

        <!-- ------------------------ LOGOS -------------------------- -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:20%;vertical-align:middle;">
              <a href="https://www.tsinghua.edu.cn/"><img style="width:105%;max-width:105%" src="images/tsinghua.jpg" alt="dise"></a>
            </td>
            <td style="padding:2.8%;width:20%;vertical-align:middle;">
              <a href="https://www.northwestern.edu"><img style="width:111.5%;max-width:111.5%" src="images/northwestern.jpg" alt="dise"></a>
            </td>
          </tr> -->
		
        <!-- </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">
                  Website template from <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>

        </td>
      </tr>
    </table>
   
    <p><center>
            <div id="clustrmaps-widget" style="width:6%">
              <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=b7mtyQom9p7zsZIJHjY71xt4m7fiicjvzctV6CkNA-s"></script>
            </div>        
            <br>
            &copy; Xiangyu Chen | Last update: April.30, 2024
    </center></p>
  </body>
</html> -->
