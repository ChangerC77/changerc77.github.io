<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Xiangyu Chen - Homepage</title>

    <meta name="author" content="Xiangyu Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Xiangyu Chen (ÈôàÁøîÂÆá)</name>
                </p>
                <p style="text-align:justify;">
                  I am currently spending my gap year as a research intern in EncoSmart, focusing on learning-based method for robot manipulation according to visual representation. 
                  Previously, I was a research assistant supervised by <a href="https://www.cityu.edu.hk/mne/people/academic-staff/prof-yin-peng">Prof.Peng Yin</a> at <a href="https://metaslam.github.io/">GAIRLAB</a>, City University of Hong Kong (CityU). 
                  I also was a research intern at ARX, <a href="https://www.discover-lab.com/">DISCOVER Lab</a>, <a href="https://air.tsinghua.edu.cn/en/"><b>Institute for AI Industry Research (AIR), Tsinghua University</b></a>.
                  where I was fortunate to work closely with <a href="https://scholar.google.com/citations?user=alz2MpAAAAAJ&hl=zh-CN&oi=sra">Dr. Yongliang Shi</a>, and <a href="https://air.tsinghua.edu.cn/info/1046/1199.htm">Prof. Guyue Zhou</a> to study SLAM and Navigation. 
                  Piror to that, I obtained First Class Honour Bachelor degree in Electrical and Electronic Engineering from Liverpoor John Moores University in UK.
                  <p>
                  <b><strong>I am actively applying for master degree and looking for the PhD opportunity in Fall 2025.</strong></b>
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:changerc77@gmail.com"><b>Email</b></a> &nbsp/&nbsp
                    <a href="Xiangyu Chen241112.pdf"><b>CV</b></a> &nbsp/&nbsp
                    <a href="https://scholar.google.jp/citations?user=nGnEAQYAAAAJ&hl=zh-CN&oi=ao"><b>Google Scholar</b></a> &nbsp/&nbsp
                    <a href="https://github.com/ChangerC77"><b>GitHub</b></a> &nbsp/&nbsp
                    <a href="https://space.bilibili.com/65857029/video"><b>Video Channel</b></a>
                </p>
              </td>
              <td style="padding:2.5%;width:48%;max-width:48%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/avator.jpg" class="hoverZoomLink"></a>
              </td>
	      </tr>
	      </table>

<!-- -------------------------- NEWS ------------------------------ -->

<!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>News</heading>
    <p>
      <li style="margin: 5px;" >
        <b>2023-09:</b>üéâPAD was accepted to NeurIPS 2023 as Poster!
      </li>
      <li style="margin: 5px;" >
        <b>2023-08:</b>üòéWelcome to <a href="GitHub - EricLee0224/awesome-nerf-editing: üßôüèª‚Äç‚ôÇÔ∏èA list of papers curated for you to dive into the Aw">awesome-nerf-editing</a>, find resource for exploring 3D editing!
      </li>
      <li style="margin: 5px;" >
        <b>2023-06:</b>üë®‚Äçüéì<a href="https://pku.ai/">PKU CoRe Lab</a> Visiting! Many thanks to Prof. <a href="https://yzhu.io/">Yixin Zhu</a>'s advices on my future study.
      </li>
      <li style="margin: 5px;" >
        <b>2023-02:</b>üéâIRFLMDNN was accepted to Neural Computing & Applications!
      </li>
      <li style="margin: 5px;" >
        <b>2022-10:</b>üéâMy graduation dissertation was selected as 2022 Beijing Outstanding Undergraduate Dissertation Award (top1%)!
      </li>
      <li style="margin: 5px;" >
        <b>2022-10:</b>üéâI successfully defended Summer Research: McADTR. Thanks to my advisors and Prof. This is an ongoing survey paper and we are conducting a systematic classification and in-depth analysis for 3D content editing based on radiance field representations (including NeRFs, 3DGS, etc.)<a href="https://ericyi.github.io/">Li Yi</a>'s insightful comments.
      </li>
      <li style="margin: 5px;" >
        <b>2022-08:</b>üòÆ‚Äçüí®I finished my visiting at CASIA and it was a pleasure to work with Lei, Yu, Xiaomeng and Xiaomin!
      </li>
    </p>
  </td>
</tr>
</tbody></table> -->

<!--  ------------------------ Research ------------------------------>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>Research Interests</heading>
    <p>
      <li style="margin: 5px;"> 
        ü§ñ<strong>Robotics</strong>
      </li>
      <li style="margin: 5px;"> 
        <strong>Embodied AI</strong>
      </li>
      <li style="margin: 5px;"> 
        <strong>Navigation</strong>
      </li>
      <li style="margin: 5px;"> 
        <strong>Robot Learning</strong>
      </li>
      <li style="margin: 5px;"> 
        <strong>Manipulation</strong>
      </li>
    </p>
  </td>
</tr>

<!--  ------------------------ Education Experience ------------------------------>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>Education</heading>
    <p>
      <li style="margin: 5px;"> 
        <strong>B.E Electrical and Electronic Engineering</strong>, Liverpoor John Moores University, UK (2019-2023) 
      </li>
    </p>
  </td>
</tr>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>Research Experience</heading>
    <p>
      <li style="margin: 5px;"> 
        Research Intern, EncoSmart (2023.11 - 2024.2, 2024.7 - 2024.11) 
      </li>
      <li style="margin: 5px;"> 
        Research Assistant, <strong>GAIRLAB, City University of Hong Kong (CityU)</strong> (2024.3 - 2024.6) 
      </li>
      <li style="margin: 5px;"> 
        Research Intern, <strong>Institute for AI Industry Research (AIR), Tsinghua University</strong> (2021.6 - 2023.12) 
      </li>
    </p>
  </td>
</tr>

<!--  ----------------------- PUBLICATIONS --------------------------  -->
</tbody></table><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Publications</heading>
    </td>
  </tr>
<!-- 	(<sup>‚Ä†</sup>: corresponding author; <sup>*</sup>: equal contribution) -->
</tbody></table>	

(<sup>‚Ä†</sup>: corresponding author; <sup>*</sup>: equal contribution)
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:14px;width:45%;max-width:45%" align="top">
        <img style="width:100%;max-width:100%" src="images/gaussiangrasper.gif" alt="dise">
    </td>
    <td width="75%" valign="center">
      <a href="https://mrsecant.github.io/GaussianGrasper/"><papertitle>GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping</papertitle></a>
      <br>
        <a href="https://mrsecant.github.io/">Yuhang Zheng</a>,
        <strong>Xiangyu Chen</strong>,
        Yupeng Zheng,
        Songen Gu,
        Runyi Yang,
        Bu Jin,
        <a href="https://philipflyg.github.io/">Pengfei Li</a>,
        Chengliang Zhong,
        Zengmao Wang,
        Lina Liu,
        Chao Yang,
        Dawei Wang,
        Zhen Chen,
        <a href="https://www.xxlong.site/">Xiaoxiao Long<sup>‚Ä†</sup>,</a> 
        Meiqing Wang<sup>‚Ä†</sup>.
      <br>
      <strong><em>RA-L, 2024</em></strong>
      <br>
      <a href="https://mrsecant.github.io/GaussianGrasper"><b>Homepage ¬∑</b></a>
      <a href="https://arxiv.org/abs/2403.09637"><b>üìëPaper ¬∑</b></a>
      <a href="GitHub - MrSecant/GaussianGrasper: [RA-L 2024] GaussianGrasper: 3D Language Gaussian Splatting for O"><b>Code</b></a>
      <br>
      <p>We introduced GaussianGrasper, a robot grasping system implemented by a 3D Gaussian field endowed with open-vocabulary semantics and accurate geometry that is capable of rapid updates to support open-world robotic grasping guided by language.</p>	
    </td>
  </tr>

  <tr>
    <td style="padding:14px;width:45%;max-width:45%" align="center">
        <img style="width:100%;max-width:100%" src="images/Block-Map-Based Localization.gif" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>Block-Map-Based Localization in Large-Scale Environment</papertitle>
      <br>
        <a href="https://yixfeng.github.io/">Yixiao Feng,</a>
        Zhou Jiang,
        Yongliang Shi,
        Yunlong Feng,
        <strong>Xiangyu Chen</strong>,
        Hao Zhao,
        Guyue Zhou.
      <br>
      <strong><em>ICRA, 2024</em></strong>
      <br>
      <a href="https://www.youtube.com/watch?v=jJhs0jK-uSI"><b>üé¨Video ¬∑</b></a>
      <a href="https://arxiv.org/pdf/2404.18192"><b>üìëPaper ¬∑</b></a>
      <a href="https://github.com/YixFeng/Block-Map-Based-Localization"><b>Code</b></a>
      <br>
      <p>we propose a localization system based on
        Block Maps (BMs) to reduce the computational load caused by
        maintaining large-scale maps.</p>	
    </td>
  </tr>

<!--  ------------------------ Patents --------------------------  -->

          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patents</heading>
              <p>
                <li style="margin: 5px;"> 
                  <b>Power low frequency oscillation data anomaly monitoring system v1.0[s]</b>, CN Software Patent No.2022SR0277090
                </li>
                <li style="margin: 5px;"> 
                  <b>Power low frequency oscillation data acquisition system v1.0[s]</b>, CN Software Patent No.2022SR0281546
                </li>
              </p>
            </td>
          </tr>
        </tbody></table> -->

<!--  ------------------------ PROJECTS --------------------------  -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Projects</heading>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-------------------------------------------------------------------->
            <tr>
              <td style="padding:14px;width:45%;max-width:45%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/mobile manipulation.gif" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Mobile Manipulation with Imitation Learning</b></papertitle>
                <p>GAIRLAB, City University of Hong Kong (CityU)</p>
              <a href="https://cckaixin.github.io/myWebsite/">Kaixin Chai, </a>
              <strong>Xiangyu Chen, </strong>
              <a href="https://space.bilibili.com/690876182/video">Yufeng Li, </a>
              <a href="https://www.cityu.edu.hk/mne/people/academic-staff/prof-yin-peng">Peng Yin</a>*
              <br>
               <a href="video/Mobile Manipulation.mp4">üé¨Video</a>
                <p>Imitation Learning(ACT)</p>
                <p>Data Collection by Teleoperation System</p>
                <p>Whole-Body Control</p>
              </td>
            </tr>      
           <!-------------------------------------------------------------------->
           <tr>
            <td style="padding:14px;width:45%;max-width:45%" align="center">
                <img style="width:100%;max-width:100%" src="./images/dynamics obstacle avoidance.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><b>Wheel-legged Robot dynamics obstacle avoidance</b></papertitle>
    <br>
    <br>
            <strong>Xiangyu Chen, </strong>
            <a href="https://space.bilibili.com/690876182/video">Yufeng Li(Hardware Design)</a>
    <br>
    <br>
              <a href="https://www.bilibili.com/video/BV1YrC9YoEfJ/?spm_id_from=333.999.0.0&vd_source=f65938b935c55207f67b4be1aaaf9b29"><b>üé¨Video</b></a>
    <br>
    <br>
              <strong>Contribution: </strong>
              <br>
              <p>Lidar-based SLAM (Cartographer)</p>  
              <p>Navigation (A* and TEB)</p>
            </td>
          </tr>
          <tr>
          <!-------------------------------------------------------------------->
            <td style="padding:14px;width:45%;max-width:45%" align="center">
                <img style="width:100%;max-width:100%" src="./images/static obstacle avoidance.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><b>Wheel-legged Robot static obstacle avoidance</b></papertitle>
  <br>
  <br>
        <strong>Xiangyu Chen, </strong>
        <a href="https://space.bilibili.com/690876182/video">Yufeng Li(Hardware Design)</a>
  <br>
  <br>
        <a href="https://www.bilibili.com/video/BV1aZxNefEU7?spm_id_from=333.788.videopod.sections&vd_source=f65938b935c55207f67b4be1aaaf9b29"><b>üé¨Video</b></a>
  <br>
  <br>
            <strong>Contribution: </strong>
            <p>Lidar-based SLAM (Cartographer)</p>  
            <p>Navigation (A* and TEB)</p>
            </td>
          </tr>
          <!-------------------------------------------------------------------->
            <tr>
              <td style="padding:14px;width:45%;max-width:45%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/3d-nav.gif" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Navigation in 3D Large-Scale Environment</b></papertitle>
		<br>
              <p>DISCOVER Lab, AIR, Tsinghua University </p>
              <strong>Xiangyu Chen</strong>,
              <a href="https://yixfeng.github.io/">Yixiao Feng,</a>
                Yunlong Feng,
                Yongliang Shi,
                Guyue Zhou.  
              <br>
              <!--<a href="video/"><b>üé¨Video</b></a>-->
              <p>Lidar-based SLAM (LIO-SAM),</p>
              <a href="https://github.com/YixFeng/Block-Map-Based-Localization"><b>block-based-localizaton</b></a>,
              <p>Navigation (A* and TEB)</p>
              </td>
            </tr>

            <!-------------------------------------------------------------------->
            <tr>
              <td style="padding:14px;width:45%;max-width:45%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/navigation_indoor.gif" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Dynamics Obstacles Avoidance Indoor</b></papertitle>
		<br>
                <p>DISCOVER Lab, AIR, Tsinghua University </p>
                <strong>Xiangyu Chen</strong>,
                <a href="https://0nhc.github.io/">Zhengxiao Han</a>,
                <a href="https://yixfeng.github.io/">Yixiao Feng</a>,
                Guyue Zhou.
              <br>      
              <!--<a href="video/"><b>üé¨Video</b></a>-->
              <p>Lidar-based SLAM (Cartographer), Vision-based SLAM (ORB_SLAM, RTAB_MAP)</p>
              <p>Extended Kalman Filter (EKF)</p>
              <p>Navigation (A* and TEB) </p>
            </p>
              </td>
            </tr>
            <!-------------------------------------------------------------------->
            <tr>
              <td style="padding:14px;width:45%;max-width:45%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/cyberdog_navigation.gif" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Cyberdog Navigation in indoor environment</b></papertitle>
		<br>
                <p>DISCOVER Lab, AIR, Tsinghua University </p>
                <strong>Xiangyu Chen</strong>,
                <a href="https://0nhc.github.io/">Zhengxiao Han</a>,
                Guyue Zhou
                <br>
                <br>
                <a href="https://www.bilibili.com/video/BV1cq4y1e7bZ/?spm_id_from=333.999.0.0"><b>üé¨Video</b></a>
                <p>Lidar-based SLAM (Cartographer)</p>
                <p>Extended Kalman Filter (EKF)</p>
                <p>Navigation (A* and TEB) </p>
              </td>
            </tr>
            <!-------------------------------------------------------------------->
            <tr>
              <td style="padding:14px;width:45%;max-width:45%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/cyberdog_slam.gif" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Cyberdog SLAM in indoor environment</b></papertitle>
		<br>
                <p>DISCOVER Lab, AIR, Tsinghua University </p>
                <strong>Xiangyu Chen</strong>,
                <a href="https://0nhc.github.io/">Zhengxiao Han</a>,
                Guyue Zhou
                <br>
                <br>
                <a href="https://www.bilibili.com/video/BV1UL411P7xM/?spm_id_from=333.999.0.0&vd_source=f65938b935c55207f67b4be1aaaf9b29"><b>üé¨Video</b></a>
                <p>Lidar-based SLAM (Cartographer)</p>
              </td>
            </tr>
            <!-------------------------------------------------------------------->
            <tr>
              <td style="padding:14px;width:45%;max-width:45%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/rl_visual_navigation.gif" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>End-to-end Visual Navigation</b></papertitle>
		<br>
                <p>DISCOVER Lab, AIR, Tsinghua University </p>
                <a>Guan Wang</a>,
                <a href="https://t6-thu.github.io/">Haoyi Niu</a>,
                <strong>Xiangyu Chen</strong>,
                Guyue Zhou
                <br>
                <br>
                <a href="video/End-to-end Visual Navigation.mp4"><b>üé¨Video</b></a>
                <p>Reinforcement Learning</p>
                <p>Sim2Real</p>
              </td>
            </tr>
            </tr>
            <!----------------Industrial Collaboration --------------------->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Industrial Collaboration</heading>
                </td>
              </tr>
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-------------------------------------------------------------------->
           <tr>
            <td style="padding:14px;width:45%;max-width:45%" align="center">
                <img style="width:100%;max-width:100%" src="./images/LLM_Mobile_Manipulation.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><b>Cooperation with iFytek: VLM for Mobile Manipulation</b></papertitle>
    <br>
    <br>
            <a href="https://philipflyg.github.io/">Pengfei Li</a>,
            <strong> Xiangyu Chen, </strong>
    <br>
    <br>
              <a href="video/LLM_Mobile_Manipulation.mp4">üé¨Video</a>
    <br>
              <p>The industrial compound mobile robot, enhanced by the capabilities of the Antelope Industrial Large Model in understanding computations, generating industrial code, and processing industrial text, can perform task comprehension, decomposition, instruction generation, and other operations through applications such as industrial task splitting, path code planning, and industrial object detection and image segmentation within a natural language interaction model. This further enhances the efficiency and effectiveness of industrial robots.
            </td>
          </tr>
          <tr>
              <!-------------------------------------------------------------------->
           <tr>
            <td style="padding:14px;width:45%;max-width:45%" align="center">
                <img style="width:100%;max-width:100%" src="./images/Baidu_Apollo_V2X.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><b>Baidu Apollo V2X Vehicle-Road Cooperative Technology Model Construction and Validation</b></papertitle>
    <br>
    <br>
            <a href="https://air.tsinghua.edu.cn/info/1026/1246.htm">Website</a>
            <p><strong>Contribution & Results</strong>: we developed a safety model based on two scenarios: ring road conflicts and unprotected left turns, and evaluated the safety performances in both individual vehicle intelligence and V2X scenarios. The results indicate that V2X improved safety metrics by 30% to 90%. 
            </p>
            <p><strong>Result</strong>: In collaboration with Baidu, contributed to the release of the first Chinese white paper on vehicle-road cooperative technology: Key technologies and prospects of vehicle-road collaboration for autonomous driving.</p>
            </td>
          </tr>
          <tr>
<!--  ------------------------ AWARDS --------------------------  -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards</heading>
              <p>
                <li style="margin: 5px;"> 
                  <b>City Special Prize</b>, "Unbounded¬∑2023 Shanghai International Student (Nationalized University Students) Innovation and Entrepreneurship Competition"
                </li>
                <li style="margin: 5px;"> 
                  City Top 10, Best Popularity Award, Second and Third Prizes, 2020„ÄÅ2022 China-U.S. Maker Competition (Shanghai Regional)
                </li>
                <li style="margin: 5px;"> 
                  Third Prize, 2021 Cross-Strait Maker Competition National Finals
                </li>
                <li style="margin: 5px;"> 
                  City Second and Third Prizes, 2019„ÄÅ2022 Shanghai College Student Maker Competition
                </li>
                <li style="margin: 5px;"> 
                  <b>First Prize (National Level)</b>, 2017 International Youth Innovation Design Competition China Region
                </li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <!--  ------------------------ MISC -------------------------- -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Hobbies</heading>
            <p style="text-align:justify;">
              Outside of research, I enjoy playing basketball.
            </p>
          </td>
        </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">
                  Website template from <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>

        </td>
      </tr>
    </table>

    <p><center>
            <div id="clustrmaps-widget" style="width:6%">
              <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=b7mtyQom9p7zsZIJHjY71xt4m7fiicjvzctV6CkNA-s"></script>
            </div>        
            <br>
            &copy; Xiangyu Chen | Last update: Nov.15, 2024
    </center></p>
  </body>
</html>

